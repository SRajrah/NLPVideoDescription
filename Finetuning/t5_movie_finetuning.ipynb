{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c760ed1-060e-40bc-b235-4bebb3da6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.12/site-packages (4.46.3)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: SentencePiece in ./.local/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: ipywidgets in ./.local/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: tdqm in ./.local/lib/python3.12/site-packages (0.0.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.12/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.local/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.12/site-packages (from datasets) (3.11.7)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.local/lib/python3.12/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.local/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in ./.local/lib/python3.12/site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.12/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in ./.local/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in ./.local/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: decorator in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from jinja2->torch) (3.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /spack/conda/envs/ood-jupyterlab-4.2/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets scikit-learn torch numpy pandas transformers torch torchvision SentencePiece ipywidgets tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0c6f39-c9fb-46f9-bf47-5ef679d9f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "movie_dataset = load_dataset('vishnupriyavr/wiki-movie-plots-with-summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75158c9a-129b-41c8-a460-7c8e571a9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759cd773-1d0a-4250-96e1-60fd53379f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd2b8b3-d79c-4e01-b1af-6085471989f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, plot_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.plot_len = plot_len\n",
    "        self.summ_len = summ_len\n",
    "        self.plot = self.data.Plot\n",
    "        self.summary = self.data.PlotSummary\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.summary)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        summary = str(self.summary[index])\n",
    "        summary = ' '.join(summary.split())\n",
    "\n",
    "        plot = str(self.plot[index])\n",
    "        plot = ' '.join(plot.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([plot], max_length= self.plot_len, pad_to_max_length=True,return_tensors='pt')\n",
    "        target = self.tokenizer.batch_encode_plus([summary], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef24c35-eeba-4e46-9953-5253db423e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42) \n",
    "np.random.seed(42) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "df = load_dataset('vishnupriyavr/wiki-movie-plots-with-summaries')['train'].to_pandas()\n",
    "df = df[['Plot','PlotSummary']]\n",
    "df.Plot = 'summarize: ' + df.Plot\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=df.sample(frac=train_size,random_state = 42)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "training_set = CustomDataset(train_dataset, tokenizer, 512, 150)\n",
    "test_dataset = CustomDataset(test_dataset, tokenizer, 512, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc100db8-4849-4cdd-9988-2ea855bfb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(loader, 0)):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if _%500==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c384ae-7845-41ed-a62d-8bab1fb2ce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home1/kmayya/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  5.334785461425781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:53,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.2019806206226349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [03:45,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.13886436820030212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [05:37,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7036545276641846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [07:29,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.4505388140678406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [09:21,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.6687629818916321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [11:13,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.07111074030399323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [13:05,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.2955981492996216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [14:57,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.2711992859840393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [16:49,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.23608450591564178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [18:41,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.22327114641666412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [20:33,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.19726236164569855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [22:25,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.48439714312553406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [24:17,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3978346884250641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [26:09,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.23358380794525146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [28:01,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.5478652715682983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [29:54,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.1907702088356018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [31:46,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3067324757575989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [33:38,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.24925020337104797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9501it [35:30,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.11719830334186554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [37:22,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.14486147463321686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10501it [39:14,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.1641826033592224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [41:06,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.1900721937417984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11501it [42:58,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.05878322571516037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [44:50,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.19467268884181976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12501it [46:42,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.11064307391643524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13001it [48:34,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3680010735988617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13501it [50:26,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.23443040251731873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13955it [52:08,  4.46it/s]\n",
      "1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.05697426199913025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [01:52,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.1989915817975998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [03:44,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.0946994200348854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [05:36,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.12068302929401398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2001it [07:28,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.32158583402633667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2501it [09:20,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.12809588015079498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3001it [11:12,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.1388021856546402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3501it [13:04,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.5018889904022217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4001it [14:56,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.09905098378658295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4501it [16:48,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.17702041566371918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5001it [18:40,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.44327524304389954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5501it [20:32,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.14732953906059265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6001it [22:25,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2651102542877197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6501it [24:17,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.20130427181720734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [26:09,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.15372690558433533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7501it [28:01,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.5726588368415833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8001it [29:53,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2907494902610779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8501it [31:45,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.6686009168624878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9001it [33:37,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.6259065270423889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9501it [35:29,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.28752151131629944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10001it [37:21,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2955506145954132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10501it [39:13,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.434964120388031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [41:05,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.6575652956962585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11501it [42:57,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.37305065989494324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [44:50,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.11604145169258118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12501it [46:42,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.17493583261966705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13001it [48:34,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.6838324666023254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13501it [50:26,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.6291471719741821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13955it [52:08,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_params = {\n",
    "    'batch_size': 2,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': 2,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "test_loader = DataLoader(test_dataset, **val_params)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "model_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa48e334-eec1-42df-8457-d21dfac35339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: A class of students wearing black gowns have gathered on a ground. A boy and a girl wearing black gowns are holding a broom. A student is flying on a broom overlooking a class of students waiting over a ground. The boys are holding a broom.\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(\"summarize: A class of students wearing black gowns have gathered on a ground. A boy and a girl wearing black gowns. The boys is holding a broom. A student is flying on a broom overlooking a class of students waiting over a ground.\", return_tensors=\"pt\")\n",
    "    inputs.to(device)\n",
    "    # Generate the output\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_length=512,  # Maximum output length\n",
    "        num_beams=5,    # Beam search for better results\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Print the result\n",
    "    print(\"Generated Output:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc4539c-6def-413d-ac5c-feb959b95e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_state, \"t5_finetuned_on_movie.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e3b24-5d64-432c-8458-376eb4bf88c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
