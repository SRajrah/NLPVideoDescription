{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (2.155.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (5.29.1)\n",
      "Requirement already satisfied: pydantic in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from google-api-core->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: datasets in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (0.26.5)\n",
      "Requirement already satisfied: packaging in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: rouge-score in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from rouge-score) (2.2.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: bert-score in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (2.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (2.2.0)\n",
      "Requirement already satisfied: requests in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: filelock in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.26.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from requests->bert-score) (2024.12.14)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nltk in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/jeffxguo/NLPVideoDescription/new_env/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install datasets\n",
    "!pip install python-dotenv\n",
    "!pip install rouge-score\n",
    "!pip install bert-score\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from rouge_score import rouge_scorer\n",
    "import ssl\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "GEMINI_API_KEY =  os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "dataset = load_dataset(\"jylins/videoxum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's imagine your favorite toy talks to you. When you talk, your toy understands what you say, and it answers you back. That's like talking to a computer that can understand our words.\n",
      "\n",
      "Natural Language Processing (NLP) makes computers understand our language. It's like giving special tools to your computer to help it \"speak\" with us. NLP helps computers read our words, listen to our voices, and even understand our jokes!\n",
      "\n",
      "Just like your toy, NLP helps computers talk to us in a way we can understand. It's like giving computers superpowers to communicate with us just like our friends.\n"
     ]
    }
   ],
   "source": [
    "# Testing if setup works \n",
    "model = genai.GenerativeModel(\"gemini-1.0-pro\")\n",
    "response = model.generate_content(\"What is Natural Language Processing? Explain it to a five year old.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_backoff(prompt: str, max_retries: int = 5, initial_delay: float = 2.0):\n",
    "        \"\"\"Helper function implementing exponential backoff\"\"\"\n",
    "        delay = initial_delay\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                return response.text\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"All attempts failed for prompt after {max_retries} retries\")\n",
    "                    return \"\"\n",
    "                sleep_time = delay * (2 ** attempt)\n",
    "                print(f\"API error: {str(e)}. Retrying in {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rouge(reference, summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, summary)\n",
    "    return scores\n",
    "\n",
    "def evaluate_bleu(reference, summary):\n",
    "    reference_tokens = reference.split()\n",
    "    summary_tokens = summary.split()\n",
    "    smoothing_function = SmoothingFunction().method4\n",
    "    score = sentence_bleu([reference_tokens], summary_tokens, smoothing_function=smoothing_function)\n",
    "    return score\n",
    "\n",
    "def evaluate_bertscore(reference, summary, model_type=\"roberta-large\"):\n",
    "    P, R, F1 = score([summary], [reference], lang=\"en\", rescale_with_baseline=True)\n",
    "    return P.mean().item(), R.mean().item(), F1.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score(text: str) -> str:\n",
    "    words = text.split()\n",
    "    num = 3\n",
    "    for word in words:\n",
    "        # Try to extract regular number\n",
    "        try:\n",
    "            # print(f\"Word: {word}\")\n",
    "            num = float(word.replace('*','').replace('[','').replace(']',''))\n",
    "            # print(f\"{num} found!\")\n",
    "            break\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return num\n",
    "\n",
    "\n",
    "# LLM As a Judge\n",
    "def evaluate_summary(summary, reference, num_evaluations=1):\n",
    "    prompt = f\"\"\"Evaluate the following video's visual summary based on six criteria:\n",
    "\n",
    "        1. Descriptiveness: How well does the summary provide a rich and vivid description of the video's content? How clear is the picture it paints of what happens in the video?\n",
    "        2. Coherence: How logically structured and easy to follow is the summary?\n",
    "        3. Completeness: Does the summary cover all important aspects of the video?\n",
    "        4. Fluency: How grammatically correct and well-written is the language in the summary?\n",
    "        5. Conciseness: How well does the summary avoid unnecessary details while covering the essentials?\n",
    "\n",
    "        Use the following scoring scale:\n",
    "        - 5: Excellent\n",
    "        - 4: Good\n",
    "        - 3: Average\n",
    "        - 2: Below average\n",
    "        - 1: Poor\n",
    "        \n",
    "        ---\n",
    "        The following are Example Scoring:\n",
    "\n",
    "        1. Descriptiveness:\n",
    "        5:\n",
    "        \"The summary captures detailed visuals and events from the video, such as 'the athlete’s grueling uphill training runs under the rain' or 'her heartfelt conversation with her coach.' It brings the scenes to life with vivid language, matching the richness of the video.\"\n",
    "        4:\n",
    "        \"The summary describes the key moments but lacks some vivid details. For example, it mentions 'training' but doesn’t describe the intense conditions shown in the video.\"\n",
    "        3:\n",
    "        \"The summary touches on important moments (e.g., training, challenges, victory) but is generic and lacks descriptive depth.\"\n",
    "        2:\n",
    "        \"The summary barely describes the events and uses vague terms like 'The athlete worked hard and succeeded,' offering little visual or emotional detail.\"\n",
    "        1:\n",
    "        \"The summary is extremely vague or devoid of descriptions, e.g., 'The video is about a runner.'”\n",
    "        \n",
    "        2. Coherence:\n",
    "        5:\n",
    "        \"The summary presents events in a clear sequence that mirrors the video’s progression: starting with training, moving through challenges, and culminating in the victory. Transitions are smooth and logical.\"\n",
    "        4:\n",
    "        \"The summary mostly follows a logical structure but includes minor jumps or skips (e.g., it moves abruptly from training to victory without mentioning the injury).\"\n",
    "        3:\n",
    "        \"The summary contains some disjointed transitions or a slightly unclear order of events, making it harder to follow.\"\n",
    "        2:\n",
    "        \"The summary is confusing and jumps between events with no logical sequence (e.g., it starts with victory, then mentions training).\"\n",
    "        1:\n",
    "        \"The summary is completely incoherent, with events presented in a random or contradictory order.\"\n",
    "       \n",
    "        3. Completeness:\n",
    "        5:\n",
    "        \"The summary covers all key events and details essential to understanding the video. It does not omit any significant aspects.\"\n",
    "        4:\n",
    "        \"The summary captures most key events but leaves out a minor detail or two that slightly reduce its completeness.\"\n",
    "        3:\n",
    "        \"The summary includes major events but omits at least one significant aspect, leaving an incomplete understanding of the video.\"\n",
    "        2:\n",
    "        \"The summary misses multiple important details, making it difficult to fully grasp the video’s core narrative.\"\n",
    "        1:\n",
    "        \"The summary barely mentions any aspects of the video, leaving out most critical events.\"\n",
    "        \n",
    "        4. Fluency:\n",
    "        5:\n",
    "        \"The summary is entirely free of grammatical errors and uses clear, polished, and natural language.\"\n",
    "        4:\n",
    "        \"The summary is mostly fluent, with minor grammatical errors or slightly awkward phrasing that doesn’t hinder comprehension.\"\n",
    "        3:\n",
    "        \"The summary is understandable but contains noticeable grammatical mistakes or unnatural phrasing that slightly disrupts reading.\"\n",
    "        2:\n",
    "        \"The summary has frequent grammatical errors or poor sentence structure, making it hard to read.\"\n",
    "        1:\n",
    "        \"The summary is riddled with grammatical errors and is incomprehensible.\"\n",
    "        \n",
    "        5. Conciseness:\n",
    "        5:\n",
    "        \"The summary is concise and covers all critical information without including irrelevant details or repetition.\"\n",
    "        4:\n",
    "        \"The summary is mostly concise but includes minor redundancies or slightly extraneous details.\"\n",
    "        3:\n",
    "        \"The summary conveys the main points but is overly wordy or contains unnecessary information.\"\n",
    "        2:\n",
    "        \"The summary is verbose, with excessive repetition or irrelevant tangents, detracting from its conciseness.\"\n",
    "        1:\n",
    "        \"The summary is excessively repetitive and includes irrelevant content that overwhelms the key points.\"\n",
    "        \n",
    "        ---\n",
    "\n",
    "        Now let's score this one. If the provided summary is describing an image instead of a video, score it as you would a video.\n",
    "        Summary: {summary}\n",
    "\n",
    "        Output in this format:\n",
    "        Descriptiveness: [Score] (Reason: [Explanation])\n",
    "        Coherence: [Score] (Reason: [Explanation])\n",
    "        Completeness: [Score] (Reason: [Explanation])\n",
    "        Fluency: [Score] (Reason: [Explanation])\n",
    "        Conciseness: [Score] (Reason: [Explanation])\"\"\"\n",
    "    aggregated_scores = {metric: [] for metric in [\"Descriptiveness\", \"Coherence\", \"Completeness\", \"Fluency\", \"Conciseness\"]}\n",
    "    \n",
    "    for _ in range(num_evaluations):\n",
    "        response = generate_with_backoff(prompt).replace('*','')\n",
    "        print(response)\n",
    "        # Extract scores from the response\n",
    "        for metric in aggregated_scores.keys():\n",
    "            if f\"{metric}:\" in response:\n",
    "                for line in response.split('\\n'):\n",
    "                    if f\"{metric}\" in line:\n",
    "                        score_line = line\n",
    "                        # print(f\"Line: {score_line}\")\n",
    "                        break\n",
    "                score = extract_score(score_line.split(f\"{metric}:\")[-1])\n",
    "                aggregated_scores[metric].append(score)\n",
    "            else:\n",
    "                print(f\"{metric} not found\")\n",
    "                aggregated_scores[metric].append(1)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    average_scores = {metric: sum(scores) / len(scores) for metric, scores in aggregated_scores.items()}\n",
    "    overall_average_score = sum(average_scores.values()) / len(average_scores)\n",
    "    average_scores['Overall_Average'] = overall_average_score    \n",
    "\n",
    "    # Calculate ROUGE and BLEU scores\n",
    "    rouge_scores = evaluate_rouge(reference, summary)\n",
    "    bleu_score = evaluate_bleu(reference, summary)\n",
    "    P, R, F1 = evaluate_bertscore(reference, summary)\n",
    "    average_scores['ROUGE-1'] = rouge_scores['rouge1'].fmeasure\n",
    "    average_scores['ROUGE-2'] = rouge_scores['rouge2'].fmeasure\n",
    "    average_scores['ROUGE-L'] = rouge_scores['rougeL'].fmeasure\n",
    "    average_scores['BLEU'] = bleu_score\n",
    "    average_scores['BERTScore_P'] = P\n",
    "    average_scores['BERTScore_R'] = R\n",
    "    average_scores['BERTScore_F1'] = F1\n",
    "\n",
    "    return average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROUGE-1': 0.23602484472049692, 'ROUGE-2': 0.0880503144654088, 'ROUGE-L': 0.1987577639751553, 'BLEU': 0.013888089110663132, 'BERTScore_P': 0.06938610225915909, 'BERTScore_R': 0.18434451520442963, 'BERTScore_F1': 0.12763485312461853}\n"
     ]
    }
   ],
   "source": [
    "reference = \"A young girl is seen sitting in a chair with a person standing next to her.  The person next to her then piercing one ear followed by the other.  The person rubs lotion on the piercings afterwards.\"\n",
    "print(evaluate_summary(\"a close-up of a young girl with blonde hair. She appears to be around 6-7 years old and has blonde hair. She is wearing a white shirt with a pink bow on the collar. The girl is looking off to the side with a serious expression on her face. A person's hand is visible on the left side of the image, holding a blue spray bottle and applying a white substance to the girl's ear. The background is blurred, but it seems like the focus is on the girl and the person applying the substance. The girl appears to be receiving a dental procedure, as she is looking up at the dentist with a concerned expression on her face. a\",reference, num_evaluations=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./summarized_dense_descriptions_1000_final (2).csv\")\n",
    "\n",
    "# How many evaluations to average\n",
    "num_evaluations = 5\n",
    "# Evaluate each summary and store the results\n",
    "baseline_results = []\n",
    "bart_results = []\n",
    "t5_movie_results = []\n",
    "t5_synthetic_results = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    reference = row['description']\n",
    "    bart_summary = row['bart_summarized_video_captions']\n",
    "    t5_movie_summary = row['t5_finetuned_on_movie_summarized_video_captions']\n",
    "    t5_synthetic_summary = row['t5_finetuned_on_synthetic_summarized_video_captions']\n",
    "\n",
    "    print(bart_summary)\n",
    "    bart_scores = evaluate_summary(bart_summary, reference, num_evaluations=num_evaluations)\n",
    "    bart_results.append(bart_scores)\n",
    "\n",
    "    print(t5_movie_summary)\n",
    "    t5_movie_scores = evaluate_summary(t5_movie_summary, reference, num_evaluations=num_evaluations)\n",
    "    t5_movie_results.append(t5_movie_scores)\n",
    "\n",
    "    print(t5_synthetic_summary)\n",
    "    t5_synthetic_scores = evaluate_summary(t5_synthetic_summary, reference, num_evaluations=num_evaluations)\n",
    "    t5_synthetic_results.append(t5_synthetic_scores)\n",
    "\n",
    "\n",
    "# Convert the results to DataFrames\n",
    "bart_results_df = pd.DataFrame(bart_results).add_prefix('bart_')\n",
    "t5_movie_results_df = pd.DataFrame(t5_movie_results).add_prefix('t5_movie_')\n",
    "t5_synthetic_results_df = pd.DataFrame(t5_synthetic_results).add_prefix('t5_synthetic_')\n",
    "\n",
    "# Combine the original DataFrame with the results\n",
    "final_df = pd.concat([df, bart_results_df, t5_movie_results_df, t5_synthetic_results_df], axis=1)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "final_df.to_csv('evaluated_summaries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
