{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66dpoBopwqaK",
        "outputId": "591bdd99-5843-45ed-fc60-4c675c208cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers timm flash_attn einops -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1qQD61txBLC",
        "outputId": "54fee843-4d01-454d-f206-f28dfc159ac2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.25.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
            "Downloading supervision-0.25.0-py3-none-any.whl (181 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/181.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "import requests\n",
        "import copy\n",
        "\n",
        "model_id = 'microsoft/Florence-2-large'\n",
        "modelDense = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval().cuda()\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n"
      ],
      "metadata": {
        "id": "nydnccPPxHes"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_example(task_prompt, text_input=None, image=None):\n",
        "    # Ensure the image is provided and is a PIL.Image object\n",
        "    if image is None or not isinstance(image, Image.Image):\n",
        "        raise ValueError(\"The 'image' parameter must be a valid PIL.Image object.\")\n",
        "\n",
        "    if text_input is None:\n",
        "        prompt = task_prompt\n",
        "    else:\n",
        "        prompt = task_prompt + text_input\n",
        "\n",
        "    # Prepare inputs\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate predictions\n",
        "    generated_ids = modelDense.generate(\n",
        "        input_ids=inputs[\"input_ids\"].cuda(),\n",
        "        pixel_values=inputs[\"pixel_values\"].cuda(),\n",
        "        max_new_tokens=1024,\n",
        "        early_stopping=False,\n",
        "        do_sample=False,\n",
        "        num_beams=3,\n",
        "    )\n",
        "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "    # Post-process and parse the answer\n",
        "    parsed_answer = processor.post_process_generation(\n",
        "        generated_text,\n",
        "        task=task_prompt,\n",
        "        image_size=(image.width, image.height)\n",
        "    )\n",
        "    return parsed_answer\n",
        "\n",
        "# Example usage\n",
        "# task_prompt = \"<DENSE_REGION_CAPTION>\"\n",
        "task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
        "image_path = \"/content/womanDancing.jpg\"  # Replace with your image path\n",
        "\n",
        "# Load the image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Run the example\n",
        "answer = run_example(task_prompt=task_prompt, image=image)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2fOc2dUxJY6",
        "outputId": "17a04cb1-2493-4f79-832b-643a9be155af"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<MORE_DETAILED_CAPTION>': 'The image shows a young woman in a dance studio. She is wearing a black sports bra and black shorts and is in the middle of a dance move. Her arms are stretched out to the sides and her legs are bent at the knees. The studio has wooden walls and large windows, allowing natural light to enter. The floor is made of light-colored wood. The woman appears to be in the process of performing a dance routine.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-G650YMa2bYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "# Load BLIP processor and model\n",
        "model_id = \"Salesforce/blip-image-captioning-base\"  # You can also try `blip-large` for better performance\n",
        "processor = BlipProcessor.from_pretrained(model_id)\n",
        "modelBlip = BlipForConditionalGeneration.from_pretrained(model_id).eval()\n"
      ],
      "metadata": {
        "id": "qu5KWR1X2Zt1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption(image):\n",
        "    # Ensure the image is a valid PIL.Image object\n",
        "    if image is None or not isinstance(image, Image.Image):\n",
        "        raise ValueError(\"The 'image' parameter must be a valid PIL.Image object.\")\n",
        "\n",
        "    # Prepare inputs for the model (only pixel_values is required)\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate caption\n",
        "    generated_ids = modelBlip.generate(\n",
        "        pixel_values=inputs[\"pixel_values\"],  # Use only pixel_values\n",
        "        max_length=50,  # Adjust based on desired caption length\n",
        "        num_beams=5,    # Beam search for better quality\n",
        "    )\n",
        "    caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/womanDancing.jpg\"  # Replace with your image path\n",
        "image = Image.open(image_path)\n",
        "\n",
        "caption = generate_caption(image)\n",
        "print(\"Generated Image Caption:\", caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CbMbev43Uvy",
        "outputId": "9fc6162e-0c7d-4619-849d-69218cb7d459"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Caption: a woman in a black leor leor leor leor leor leor leor leor leor leor leor leo\n"
          ]
        }
      ]
    }
  ]
}